# @package _global_

# CIFAR-100 CNN Benchmark - Improved
# Target performance: 55-70% accuracy

defaults:
  - override /data: cifar100
  - override /model: cifar100_cnn_1m_improved
  - override /callbacks: default
  - override /trainer: default

task_name: "cifar100_benchmark_cnn_improved"

tags: ["cifar100", "cnn", "benchmark", "1m_params", "improved"]

seed: 42

trainer:
  min_epochs: 50
  max_epochs: 200
  gradient_clip_val: 1.0

# Data augmentation is crucial for CIFAR-100
data:
  batch_size: 128
  num_workers: 0
  pin_memory: true
  # Add augmentation parameters if your datamodule supports them
  train_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.RandomCrop
        size: 32
        padding: 4
      - _target_: torchvision.transforms.RandomHorizontalFlip
        p: 0.5
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [0.5071, 0.4867, 0.4408]
        std: [0.2675, 0.2565, 0.2761]

logger:
  wandb:
    tags: ${tags}
    group: "cifar100_benchmark"
  aim:
    experiment: "cifar100_benchmark"
