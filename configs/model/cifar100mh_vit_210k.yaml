_target_: src.models.multihead_vimh_module.MultiheadLitModule

net:
  _target_: src.models.components.vision_transformer.VisionTransformer
  n_channels: 3     # CIFAR-100-MH has 3 color channels
  image_size: 32    # CIFAR-100-MH is 32x32
  patch_size: 4     # Smaller patches for 32x32 images
  embed_dim: 384    # Embedding dimension
  n_layers: 12      # Number of transformer layers
  n_attention_heads: 6  # Number of attention heads
  forward_mul: 2    # Forward multiplier
  output_size: 100  # Default - will be overridden by dataset (single head)
  dropout: 0.1

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.01

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: 100
  eta_min: 1e-5

# Different criterion per head (will be auto-configured based on dataset)
criteria:
  param_0:
    _target_: torch.nn.CrossEntropyLoss
  param_1:
    _target_: torch.nn.CrossEntropyLoss

# Loss weighting (equal weight to all heads by default)
loss_weights:
  param_0: 1.0
  param_1: 1.0

compile: false

# Auto-configure heads from dataset metadata
# Note: VisionTransformer doesn't support multihead natively, so disable auto-config
auto_configure_from_dataset: false
