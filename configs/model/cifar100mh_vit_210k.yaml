_target_: src.models.multihead_lit_module.MultiheadLitModule

net:
  _target_: src.models.components.vision_transformer.VisionTransformer
  n_channels: 3 # CIFAR-100-MH has 3 color channels
  image_size: 32 # CIFAR-100-MH is 32x32
  patch_size: 4 # Smaller patches for 32x32 images
  embed_dim: 384 # Embedding dimension
  n_layers: 12 # Number of transformer layers
  n_attention_heads: 6 # Number of attention heads
  forward_mul: 2 # Forward multiplier
  output_size: 100 # Default - will be overridden by dataset (single head)
  dropout: 0.1

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.01

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: 100
  eta_min: 1e-5

# Different criterion per head (will be auto-configured based on dataset)
criteria:
  param_0:
    _target_: torch.nn.CrossEntropyLoss
  param_1:
    _target_: torch.nn.CrossEntropyLoss

# Loss weighting auto-configured from dataset JNDs (Just Noticeable Differences)
# JND-based weights: fine_label=100, coarse_label=20, texture=8 (based on number of classes)
# loss_weights: # Commented out - auto-configured from dataset metadata
