_target_: src.models.multihead_module.MultiheadLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0001

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

# Ordinal regression loss for quantized continuous parameters
# This considers numerical distance between predicted and actual values
# Loss is normalized to [0,1] range for better multi-head training
criteria:
  note_number:
    _target_: src.models.losses.OrdinalRegressionLoss
    num_classes: 256
    regression_loss: l1  # L1 loss for continuous values
    alpha: 0.1  # Weight for classification regularization
    normalize_loss: true  # Normalize to [0,1] range
  note_velocity:
    _target_: src.models.losses.OrdinalRegressionLoss
    num_classes: 256
    regression_loss: l1  # L1 loss for continuous values
    alpha: 0.1  # Weight for classification regularization
    normalize_loss: true  # Normalize to [0,1] range

# Loss weighting (equal weight to all heads by default)
loss_weights:
  note_number: 1.0
  note_velocity: 1.0

net:
  _target_: src.models.components.simple_cnn.SimpleCNN
  input_channels: 3  # VIMH typically has 3 color channels for spectrograms
  conv1_channels: 64
  conv2_channels: 128
  fc_hidden: 512
  heads_config:
    note_number: 256  # Default - will be overridden by dataset
    note_velocity: 256  # Default - will be overridden by dataset
  dropout: 0.5
  input_size: 32  # VIMH image size (32x32 for spectrograms)

compile: false

# Auto-configure heads from dataset metadata
auto_configure_from_dataset: true
