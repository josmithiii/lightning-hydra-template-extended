_target_: src.models.mnist_module.MNISTLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0001  # weight decay for EfficientNet

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

criterion:
  _target_: torch.nn.CrossEntropyLoss

net:
  _target_: src.models.components.simple_efficientnet.SimpleEfficientNet
  input_channels: 1
  num_classes: 10
  width_mult: 0.043  # Scaled down to ~66k parameters
  depth_mult: 0.7    # Reduced depth for parameter budget
  dropout_rate: 0.2

# compile model for faster training with pytorch 2.0
compile: false
