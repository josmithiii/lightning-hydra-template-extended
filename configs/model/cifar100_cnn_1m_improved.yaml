_target_: src.models.mnist_module.MNISTLitModule

optimizer:
  _target_: torch.optim.SGD  # SGD often works better for CIFAR-100
  _partial_: true
  lr: 0.1  # Higher initial LR with SGD
  momentum: 0.9
  weight_decay: 0.0005  # Slightly higher weight decay

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR  # Smoother decay
  _partial_: true
  T_max: 200
  eta_min: 0.0001

criterion:
  _target_: torch.nn.CrossEntropyLoss
  label_smoothing: 0.1  # Helps with 100-class classification

net:
  _target_: src.models.components.simple_cnn.SimpleCNN
  input_channels: 3
  conv1_channels: 96   # Increased from 64
  conv2_channels: 192  # Increased from 128
  fc_hidden: 768       # Increased from 512
  output_size: 100
  dropout: 0.4         # Reduced from 0.5 (less aggressive)
  input_size: 32

# compile model for faster training with pytorch 2.0
compile: false
