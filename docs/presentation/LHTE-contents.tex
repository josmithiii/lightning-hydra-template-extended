% Created 2025-09-15 by jos from /l/asm/ and /l/mt/ADCxGather2025.tex

%% \begin{emptyslide}[toc={}]{}
%% %\vspace{\stretch{1}}
%% \vspace{-1.44em}
%% \myFigureRotateToBox{ADCxGather-2025-title-both}{-90}{\twidth}{\theight}{}
%% %\myFigureRotateToBox{ADCxGather-video-zoom-background}{-90}{\twidth}{\theight}{}
%% \vspace{\stretch{1}}
%% \end{emptyslide}

\section[toc={Lightning Hydra Template \emph{Ext}}]{{PyTorch Lightning Hydra Template \emph{Extended} (LHTE)}}

\begin{emptyslide}[toc={}]{}
\vspace{-1.44em}
\myFigureRotateToBox{ADCxGather-2025-title-part1}{-90}{\twidth}{\theight}{}
%\myFigureRotateToBox{ADCxGather-2025-title-LHTE}{-90}{\twidth}{\theight}{}
\vspace{\stretch{1}}
\end{emptyslide}

\begin{slide}[\slideopts,toc={Lightning Hydra Template Ext}]{Lightning Hydra Template Extended (LHTE) --- New Architectures and Datasets}

% ADCxGather2025 abstract 2025-08-24

\vspace{-1em}
  
% Final onboarding: https://conference.audio.dev/wp-admin/post.php?post=25949&action=edit&var=registration

  \begin{itemize}

    \mpitem Extends basic Pytorch Lightning+Hydra Template with state-of-the-art image-classification architectures and dataset support

    \mpitem LHTE began as a fork of the \emph{Lightning Hydra Template (LHT):} \url{https://github.com/ashleve/lightning-hydra-template}
    \begin{itemize}

      \mpitem \emph{PyTorch Lightning} streamlines deep-learning model development in
      numerous ways

      \mpitem \emph{Hydra} is a powerful configuration management framework often used

      \mpitem An LHT \emph{example experiment} trains an MLP on MNIST (hand-written digits)

    \end{itemize}

    \mpitem LHTE adds \emph{more architectures:} CNNs, ConvNeXt, EfficientNet, ViT

    \mpitem LHTE adds \emph{more datasets:} CIFAR-10, CIFAR-100, VIMH

    \mpitem Variable Image Multi-Head (VIMH) format generalizes CIFAR-100:
    \begin{itemize}
      \mpitem Up to 65k x 65k images with up to 65k channels (``stacked spectral representations'')
      \mpitem \emph{Multi-Head ready:} Up to 65k \emph{labeled parameters} (8-bit label, 8-bit value)
      \mpitem Nice for \emph{synthesis parameters} (up to 128 parameters, up to 128 settings each)
      % pairs with \emph{multiple classification / regression heads}
      %% \begin{itemize}
      %%   \mpitem Up to 256 parameters (8 bits)
      %%   \mpitem Up to 256 values for each parameter (8 bits)
      %% \end{itemize}
      \mpitem \emph{Data loaders} for the various datasets and model architectures
      \mpitem The \texttt{configs/experiment/} directory contains \emph{benchmark replications} % on MNIST, CIFAR, and VIMH datasets
      \mpitem Top-level \texttt{Makefile} contains $\approx100$ \emph{make targets} for tests, training, experiments
    \end{itemize}
  \end{itemize}

\end{slide}

\begin{slide}[\slideopts,toc={Original LHT}]{Original Lightning Hydra Template (LHT)}

  \emph{Open-Source PyTorch Lightning + Hydra Bootstrap}

  \begin{itemize}
    \mpitem Opinionated project skeleton with \texttt{src/}, \texttt{configs/}, and \texttt{tests/} ready for research

    \mpitem \emph{Hydra-first workflow:} CLI overrides (e.g., \texttt{python src/train.py trainer=gpu data.batch\_size=64}) for every configuration value

    \mpitem \emph{PyTorch Lightning baseline:} single-head MNIST MLP experiment, reproducible training loops, and logging hooks

    \mpitem Built-in developer experience: make targets for testing/formatting, Conda or pip installation paths, and template README for new repos

    \mpitem Stable foundation the LHTE fork keeps compatible so existing configs, datasets, and weights continue to run unchanged
  \end{itemize}

\end{slide}

\begin{slide}[\slideopts,toc={Why LHTE}]{Why Lightning Hydra Template \emph{Extended}?}

  \emph{Motivation for the Fork}

  \begin{itemize}
    \mpitem One repo, many backbones: SimpleCNN, ConvNeXt-V2, EfficientNet, ViT, SDN, and multihead MLPs ship side by side

    \mpitem Out-of-the-box datasets beyond MNIST: CIFAR-10/100, multihead synth suites, and the new Variable Image MultiHead (VIMH) format

    \mpitem Hydra-first overrides encourage rapid prototyping --- swap data, models, trainers, and losses without touching code

    \mpitem Developer ergonomics matter: 100+ make targets, scripted smoke tests, and diagram tooling keep the feedback loop tight

    \mpitem Everything remains compatible with upstream LHT so existing configs and checkpoints keep working
  \end{itemize}

\end{slide}

\begin{slide}[\slideopts,toc={LHTE Tour}]{LHTE in 5 Minutes}

  \emph{Hands-On Preview}

  \begin{itemize}
    \mpitem \texttt{sh setup.sh} to bootstrap a uv-managed virtual environment with PyTorch + Lightning

    \mpitem \texttt{make h} surfaces discoverable commands; \texttt{make tqa} runs MNIST smoke trains across every architecture

    \mpitem CIFAR baselines: \texttt{make cbqa} (quick sanity), \texttt{make cbs10/cbs100} (full benchmarks with logs)

    \mpitem Real multihead workloads: \texttt{python src/train.py experiment=vimh\_cnn} auto-configures heads from dataset metadata

    \mpitem Mix and match with CLI overrides such as \texttt{trainer.max\_epochs=1} or \texttt{model.loss=focal} to explore variants
  \end{itemize}

\end{slide}

\begin{slide}[\slideopts,toc={Feature Map}]{Feature Map \& Documentation Trail}

  \emph{Where to Dive Deeper}

  \begin{itemize}
    \mpitem Architectures roundup: \texttt{docs/architectures.md} for parameter counts, diagrams, and recommended use cases

    \mpitem Dataset guide: \texttt{docs/vimh.md} + \texttt{docs/vimh\_cookbook.md} explain the metadata schema and sampling recipes

    \mpitem Benchmark ledger: \texttt{docs/benchmarks.md} documents CIFAR + VIMH comparisons with reproducible Hydra configs

    \mpitem Multihead strategy: \texttt{docs/multihead.md} covers head wiring, loss combinations, and evaluation metrics

    \mpitem Vision primer handout: \texttt{docs/vision\_primer.md} mirrors these slides for quick sharing without LaTeX
  \end{itemize}

\end{slide}

\begin{slide}[\slideopts,toc={Talk Flow}]{Suggested Talk Flow}

  \emph{Use LHTE to Frame Your Story}

  \begin{itemize}
    \mpitem Start with the Lightning + Hydra reuse pitch, then highlight how LHTE supercharges it with modern backbones

    \mpitem Walk through the architecture menu and pair each backbone with a ready-to-run experiment

    \mpitem Demo quick wins: smoke tests, CIFAR comparisons, and VIMH runs with a few terminal commands

    \mpitem Land on multihead motivation and roadmap --- point to benchmark snapshots and upcoming extensions

    \mpitem Close by inviting the audience to clone the repo, open \texttt{docs/index.md}, and follow the handout for self-serve exploration
  \end{itemize}

\end{slide}

\section[toc={New Architectures}]{LHTE Neural Architectures Beyond MLP}

\begin{slidewhite}[\slideopts,toc={CNN}]{SimpleCNN Architecture}
  
  \emph{Convolutional Neural Network for Spatial Feature Extraction}
  
  \vspace{1em}

  \centerline{\includegraphics[width=\textwidth]{cnn_architecture.eps}}

  \begin{itemize}
    \mpitem \emph{Two conv layers:} 3×3 kernels, 32→64 channels, MaxPool, BatchNorm
    
    \mpitem \emph{Adaptive pooling:} 7×7 feature maps → FC classifier with dropout
    
    \mpitem \emph{Parameter variants:} 8K (small), 68K (medium), 421K (large)
    
    \mpitem \emph{Performance:} CIFAR-10: 85-92\%, CIFAR-100: 55-70\%
    
    \mpitem Supports multihead classification for multi-task learning
  \end{itemize}
  
\end{slidewhite}

\begin{slide}[\slideopts,toc={ConvNeXt}]{ConvNeXt-V2 Architecture}
  
  \emph{Modern CNN with Global Response Normalization (GRN)}
  
  \begin{itemize}
    \mpitem \emph{Key innovation:} GRN normalizes across spatial/channel dimensions
    
    \mpitem \emph{Architecture:} 7×7 depthwise conv, LayerNorm, 4× MLP with GELU
    
    \mpitem \emph{Sizes:} Tiny (18K), Small (73K), Base (288K), Large (725K)
    
    \mpitem \emph{Best performer:} CIFAR-10: 90-95\%, CIFAR-100: 70-80\%
  \end{itemize}
  
  \vspace{0.5em}
  \centerline{\includegraphics[width=\textwidth]{convnext_architecture.eps}}
\end{slide}

\begin{slide}[\slideopts,toc={EfficientNet}]{EfficientNet Architecture}
  
  \emph{Optimized CNN for Mobile and Edge Deployment}
  
  \begin{itemize}
    \mpitem \emph{Compound scaling:} Balances depth, width, and resolution
    
    \mpitem \emph{Mobile-optimized:} Inverted residuals, squeeze-excitation, Swish
    
    \mpitem \emph{Sizes:} 22K (edge), 210K (balanced), 7M (high accuracy)
    
    \mpitem \emph{Performance:} CIFAR-10: 89-94\%, CIFAR-100: 67-77\%
  \end{itemize}
  
  \vspace{0.5em}
  \centerline{\includegraphics[width=\textwidth]{efficientnet_architecture.eps}}
\end{slide}

\begin{slide}[\slideopts,toc={ViT}]{Vision Transformer (ViT) Architecture}
  
  \emph{Attention-Based Learning on Image Patches}
  
  \begin{itemize}
    \mpitem \emph{Image → Patches:} 28×28 → 7×7 patches → token sequence
    
    \mpitem \emph{Self-attention:} Multi-head attention + MLP with GELU
    
    \mpitem \emph{Sizes:} Tiny (38K), Small (210K, MNIST SOTA: 99.5\%), Base (821K)
    
    \mpitem Highly parallelizable, scales with data and compute
  \end{itemize}
  
  \vspace{0.5em}
  \centerline{\includegraphics[width=\textwidth]{vit_architecture.eps}}
\end{slide}

\section[toc={New Dataset Formats}]{Datasets Beyond MNIST}

\begin{slide}[\slideopts,toc={CIFAR-10}]{CIFAR-10 Dataset Support}
  
  \emph{Standard Computer Vision Benchmark}
  
  \begin{itemize}
    \mpitem 10 classes, 32×32 RGB, 50K train / 10K test
    
    \mpitem \emph{LHTE Results:}
    %% \begin{itemize}
    %%   \mpitem CNN (85-92\%)
    %%   \mpitem ConvNeXt (90-95\%)
    %%   \mpitem ViT (88-93\%)
    %% \end{itemize}
    \mpitem \emph{LHTE Results:} CNN (85-92\%), ConvNeXt (90-95\%), ViT (88-93\%)
    
    \mpitem \emph{Commands:} \texttt{make cbq10c} (quick), \texttt{make cb10c} (full)
    
    \mpitem Literature-competitive performance out-of-the-box
  \end{itemize}
  
  \vspace{0.5em}
  \centerline{\includegraphics[width=0.6\textwidth]{cifar10_samples.eps}}
\end{slide}

\begin{slide}[\slideopts,toc={CIFAR-100}]{CIFAR-100 Dataset Support}
  
  \emph{Fine-Grained Classification Challenge}
  
  \begin{itemize}
    \mpitem 100 fine classes or 20 coarse superclasses, 32×32 RGB
    
    \mpitem \emph{Performance:} ConvNeXt leads at 70-80\% (fine), 85\% (coarse)
    
    \mpitem \emph{Multihead:} Simultaneous fine + coarse classification
    
    \mpitem \emph{Commands:} \texttt{make cb100c}, \texttt{make cbs100}
  \end{itemize}
  
  \vspace{0.5em}
  \centerline{\includegraphics[width=0.7\textwidth]{cifar100_samples.eps}}
\end{slide}

\begin{slidewhite}[\slideopts,toc={VIMH}]{Variable Image MultiHead (VIMH) Format}
  \vspace{-1em}
  
  \emph{Generalized Dataset Format for Multi-Parameter Learning}
  
  \begin{itemize}
    \mpitem \emph{Self-describing:} Variable dimensions up to 65k×65k×65k (16-bit metadata)
    
    \mpitem \emph{Flexible labels:} 0-255 parameters, 8-bit quantized (~100 steps)
    
    \mpitem \emph{Per sample:} [height, width, channels] + [N params] + [ID,val pairs] + image
    
    \mpitem \emph{Applications:} Audio spectrograms, vision, scientific data
    
    \mpitem Models auto-configure from dataset metadata
  \end{itemize}
  \vspace{-4em}
  \myFigureRotateToBox{vimh-proj}{-90}{\twidth}{0.45\theight}{}
\end{slidewhite}
  
%% \begin{slide}[\slideopts,toc={}]{Variable Image MultiHead (VIMH) Format}
%%   \centerline{\includegraphics[width=0.9\textwidth]{png/sample_data.eps}}
%% \end{slide}


\begin{slide}[\slideopts,toc={MultiHead}]{Multi-Head Classification Support}
  
  \emph{Training Networks with Multiple Output Tasks}
  
  \begin{itemize}
    \mpitem \emph{Architecture:} Shared backbone → separate heads per task
    
    \mpitem \emph{Task types:} Classification, ordinal regression, pure regression
    
    \mpitem \emph{Examples:} MNIST (digit+thickness), CIFAR-100 (fine+coarse)
    
    \mpitem Configurable via Hydra without code changes
  \end{itemize}
  
  %\vspace{0.5em}
  % \centerline{\includegraphics[width=0.5\textwidth]{viz/diagrams/multihead_architecture.eps}}
  \scalebox{0.7}{
    \input multihead.tex
  }
\end{slide}
%% \begin{slide}[\slideopts,toc={}]{Multi-Head Classification Support}
%%   \scalebox{1.0}{
%%     \input multihead.tex
%%   }
%% \end{slide}

\begin{slide}[\slideopts,toc={Benchmarks}]{Benchmark Replications \& Experiments}
  
  \emph{50+ Pre-Configured Experiments}
  
  \begin{itemize}
    \mpitem \emph{Categories:} MNIST, CIFAR-10/100, VIMH, Multihead
    
    \mpitem \emph{Features:} Fixed seeds, fair comparisons, automated tracking
    
    \mpitem \emph{Commands:} \texttt{make ca} (compare), \texttt{make cbqa} (quick), \texttt{make cbsa} (full)
    
    \mpitem Version-controlled configs ensure reproducibility
  \end{itemize}
\end{slide}

\begin{slide}[\slideopts,toc={Makefile}]{100+ Makefile Targets}
  
  \emph{Streamlined Research Workflow}
  
  \begin{itemize}
    \mpitem \emph{Abbreviations:} \texttt{t*} (train), \texttt{tq*} (quick), \texttt{cb*} (CIFAR), \texttt{e*} (experiments)
    
    \mpitem \emph{Progressive testing:} \texttt{tq} → \texttt{ca} → \texttt{cbqa} → \texttt{cbs}
    
    \mpitem \emph{Productivity:} \texttt{make help}, logical naming, batch operations
  \end{itemize}
\end{slide}

\papersection{Future Work}{

  Next Steps:
  \BIT
  \mpitem Merge PRs
  \mpitem Periodic Chatbot Review (GPT-Codex, Claude, Gemini, \dots)
  \EIT
}

\begin{slide}[\slideopts,toc={}]{Summary of Resources Online}
  \begin{itemize}
    \item \emph{Neural Spectral Modeling Template (NSMT):}\\
      \href{https://github.com/josmithiii/neural-spectral-modeling-template.git}
           {\texttt{github.com/josmithiii/neural-spectral-modeling-template}}
    \item[]
    \item \emph{Lightning Hydra Template Extended (LHTE):}\\
      \href{https://github.com/josmithiii/lightning-hydra-template-extended.git}
           {\texttt{github.com/josmithiii/lightning-hydra-template-extended}}
    \item[]
    \item \emph{Lightning Hydra Template (LHT):}\\
      \href{https://github.com/ashleve/lightning-hydra-template}
           {\texttt{github.com/ashleve/lightning-hydra-template}}
    \item[]
    \item JOS Home Page (Videos, Overheads, including these):\\
      \href{https://ccrma.stanford.edu/~jos/Welcome.html}
           {\texttt{https://ccrma.stanford.edu/\~{}jos/}}
  \end{itemize}
\end{slide}
