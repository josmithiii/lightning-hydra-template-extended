h help:  ## Show help
	@grep -E '^[.a-zA-Z0-9_ -]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

c clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

cl clean-logs: ## Clean logs
	rm -rf logs/**

f format: ## Run pre-commit hooks
	pre-commit run -a

s sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

a activate: ## Activate the uv environment
	@echo "Add to ~/.tcshrc: alias a 'echo \"source .venv/bin/activate.csh\" && source .venv/bin/activate.csh'"
	@echo "Then just type: a"

d deactivate: ## Deactivate the uv environment
	@echo "Add to ~/.tcshrc: alias d 'echo deactivate && deactivate'"
	@echo "Then just type: d"

# TRAINING TARGETS "tr"

tr train train-sdn: ## Train the default model (a small SimpleDenseNet) 
	time python src/train.py


trc trcnn train-cnn: ## Train with CNN architecture
	time python src/train.py model=mnist_cnn_small

trvs train-vit-small: ## Train small ViT (~38K params)
	time python src/train.py model=mnist_vit_38k

trvm train-vit-medium: ## Train with ViT architecture (~210K params)
	time python src/train.py model=mnist_vit_210k

trvl train-vit-large: ## Train large ViT (~821K params)
	time python src/train.py model=mnist_vit_821k


trvp train-vit-pytorch: ## Train ViT using PyTorch layers
	time python src/train.py model=mnist_vit_pytorch

trcns train-convnext-small: ## Train ConvNeXt-V2 small (~68K params)
	time python src/train.py model=mnist_convnext_68k

trcnm train-convnext-medium: ## Train ConvNeXt-V2 medium (~210K params)
	time python src/train.py model=mnist_convnext_210k

trcnl train-convnext-large: ## Train ConvNeXt-V2 large (~821K params)
	time python src/train.py model=mnist_convnext_821k



# TRAIN-QUICKLY TARGETS "tq"

tq train-quick: ## Train quickly SimpleDenseNet, 1 epoch
	python src/train.py trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqc train-quick-cnn: ## Train quickly SimpleCNN, 1 epoch
	python src/train.py model=mnist_cnn trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqv train-quick-vit: ## Train quickly ViT, 1 epoch
	python src/train.py model=mnist_vit_38k trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqcn train-quick-convnext: ## Train quickly ConvNeXt-V2, 1 epoch
	python src/train.py model=mnist_convnext_68k trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqa train-quick-all: tq tqc tqv tqcn ## Train quickly all architectures supported

# TESTING TARGETS "t"

t test: ## Run fast pytest tests
	pytest -k "not slow"

ta test-all: ## Run all pytest tests
	pytest

td test-diagram: ## Generate model architecture diagrams (text + graphical)
	python viz/enhanced_model_diagrams.py

tda test-diagram-all: ## Generate diagrams for all model architectures
	python viz/enhanced_model_diagrams.py -c mnist_cnn_8k
	python viz/enhanced_model_diagrams.py -c mnist_vit_38k
	python viz/enhanced_model_diagrams.py -c mnist_convnext_68k
	python viz/enhanced_model_diagrams.py -c mnist_sdn_8k

tdl test-diagram-list: ## List available model configs for diagrams
	python viz/enhanced_model_diagrams.py --list-configs

tds test-diagram-simple: ## Generate simple text-only diagrams
	python viz/simple_model_diagram.py

ca compare-arch: ## Compare architectures on quick runs
	@echo "=== Training SimpleDenseNet ==="
	python src/train.py trainer.max_epochs=3 tags="[arch_comparison,dense]"
	@echo "=== Training SimpleCNN ==="
	python src/train.py model=mnist_cnn trainer.max_epochs=3 tags="[arch_comparison,cnn]"
	@echo "=== Training ViT ==="
	python src/train.py model=mnist_vit_38k trainer.max_epochs=3 tags="[arch_comparison,vit]"
	@echo "=== Training ConvNeXt-V2 ==="
	python src/train.py model=mnist_convnext_68k trainer.max_epochs=3 tags="[arch_comparison,convnext]"
	@echo "=== Check logs/ directory for results comparison ==="

# EXPERIMENTS "e" - Reproducible Configuration Examples

e esdn exp-sdn: ## Run original example experiment (reproducible baseline)
	time python src/train.py experiment=example

evit exp-vit: ## Run ViT experiment
	time python src/train.py experiment=vit_mnist


ev995 exp-vit-995: ## Run ViT experiment achieving SOTA 99.5% validation accuracy
	time python src/train.py experiment=mnist_vit_995
	# == python src/train.py model=mnist_vit_995 data=mnist_vit_995 trainer.max_epochs=200 trainer.min_epochs=10 trainer.gradient_clip_val=1.0 data.batch_size=128 seed=12345 tags="[mnist,vit,995,optimized]"

emhc exp-multihead-cnn: ## Run MultiHead CNN classification experiment
	time python src/train.py experiment=multihead_cnn_mnist

excn exp-convnext: ## Run ConvNeXt-V2 experiment
	time python src/train.py experiment=convnext_mnist

ecnb exp-convnext-benchmark: ## Run official ConvNeXt V2-Tiny benchmark (acid test)
	time python src/train.py experiment=convnext_v2_official_tiny_benchmark

