h help:  ## Show help
	@grep -E '^[.a-zA-Z0-9_ -]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

c clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

cl clean-logs: ## Clean logs
	rm -rf logs/**

f format: ## Run pre-commit hooks
	pre-commit run -a

s sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

a activate: ## Activate the uv environment
	@echo "Add to ~/.tcshrc: alias a 'echo \"source .venv/bin/activate.csh\" && source .venv/bin/activate.csh'"
	@echo "Then just type: a"

d deactivate: ## Deactivate the uv environment
	@echo "Add to ~/.tcshrc: alias d 'echo deactivate && deactivate'"
	@echo "Then just type: d"

# TRAINING TARGETS "tr"

tr train train-sdn: ## Train the default model (a small SimpleDenseNet) 
	time python src/train.py


trc trcnn train-cnn: ## Train with CNN architecture
	time python src/train.py model=mnist_cnn_small


trv trvit train-vit: ## Train with ViT architecture 
	time python src/train.py model=mnist_vit_210k


trvs train-vit-small: ## Train small ViT (~38K params)
	time python src/train.py model=mnist_vit_38k


trvl train-vit-large: ## Train large ViT (~821K params)
	time python src/train.py model=mnist_vit_821k


trvp train-vit-pytorch: ## Train ViT using PyTorch layers
	time python src/train.py model=mnist_vit_pytorch






# TRAIN-QUICKLY TARGETS "tq"

tq train-quick: ## Train quickly SimpleDenseNet, 1 epoch
	python src/train.py trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqc train-quick-cnn: ## Train quickly SimpleCNN, 1 epoch
	python src/train.py model=mnist_cnn trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqv train-quick-vit: ## Train quickly ViT, 1 epoch
	python src/train.py model=mnist_vit_38k trainer.max_epochs=1 +trainer.limit_train_batches=10 +trainer.limit_val_batches=5

tqa train-quick-all: tq tqc tqv ## Train quickly all architectures supported

# TESTING TARGETS "t"

t test: ## Run fast pytest tests
	pytest -k "not slow"

ta test-all: ## Run all pytest tests
	pytest

ca compare-arch: ## Compare architectures on quick runs
	@echo "=== Training SimpleDenseNet ==="
	python src/train.py trainer.max_epochs=3 tags="[arch_comparison,dense]"
	@echo "=== Training SimpleCNN ==="
	python src/train.py model=mnist_cnn trainer.max_epochs=3 tags="[arch_comparison,cnn]"
	@echo "=== Training ViT ==="
	python src/train.py model=mnist_vit_38k trainer.max_epochs=3 tags="[arch_comparison,vit]"
	@echo "=== Check logs/ directory for results comparison ==="

# EXPERIMENTS "e" - Reproducible Configuration Examples

e esdn exp-sdn: ## Run original example experiment (reproducible baseline)
	time python src/train.py experiment=example

evit exp-vit: ## Run ViT experiment
	time python src/train.py experiment=vit_mnist


ev995 exp-vit-995: ## Run ViT experiment achieving SOTA 99.5% validation accuracy
	time python src/train.py experiment=mnist_vit_995
	# == python src/train.py model=mnist_vit_995 data=mnist_vit_995 trainer.max_epochs=200 trainer.min_epochs=10 trainer.gradient_clip_val=1.0 data.batch_size=128 seed=12345 tags="[mnist,vit,995,optimized]"

emhc exp-multihead-cnn: ## Run MultiHead CNN classification experiment
	time python src/train.py experiment=multihead_cnn_mnist

